RGB_levels$freq
RGB_levels$Freq
n_resize <- 128
img <- resize(img, n_resize, n_resize)
RGB_levels$Freq/(n_resieze^2)
RGB_levels$Freq/(n_resize^2)
View(RGB_levels)
n_intervals <- 11
intervals_RGB <- seq(0,1,length.out = n_intervals)
n_files <- length(list.files(img_dir))
n_names <- list.files(img_dir)
RGB <- data.frame(matrix(NA, n_files, 1001))
colnames(RGB) <- c("Image", paste("RGB_", 1:1000, sep = ""))
RGB$Image <- n_names
img <- readImage(paste(img_dir, n_names[1], sep = ""))
img_data <- imageData(img)
RGB_data <- img_data
RGB_levels <- as.data.frame(table(
factor(findInterval(RGB_data[,,1], intervals_RGB), levels = 1:n_intervals),
factor(findInterval(RGB_data[,,2], intervals_RGB), levels = 1:n_intervals),
factor(findInterval(RGB_data[,,3], intervals_RGB), levels = 1:n_intervals)
))
n_resize <- 128
n_intervals <- 10
intervals_RGB <- seq(0,1,length.out = n_intervals)
n_files <- length(list.files(img_dir))
n_names <- list.files(img_dir)
RGB <- data.frame(matrix(NA, n_files, n_intervals^3))
colnames(RGB) <- c("Image", paste("RGB_", 1:1000, sep = ""))
colnames(RGB) <- c("Image", paste("RGB_", 1:n_intervals^3, sep = ""))
RGB <- data.frame(matrix(NA, n_files, n_intervals^3+1))
RGB$Image <- n_names
img <- readImage(paste(img_dir, n_names[1], sep = ""))
img <- resize(img, n_resize, n_resize)
img_data <- imageData(img)
RGB_data <- img_data
RGB_levels <- as.data.frame(table(
factor(findInterval(RGB_data[,,1], intervals_RGB), levels = 1:n_intervals),
factor(findInterval(RGB_data[,,2], intervals_RGB), levels = 1:n_intervals),
factor(findInterval(RGB_data[,,3], intervals_RGB), levels = 1:n_intervals)
))
RGB_levels$Freq/(n_resize^2)
RGB[1,2:ncol(RGB)] <- RGB_levels$Freq/(n_resize^2)
RGB_levels$Freq/(n_resize^2)
RGB <- data.frame(matrix(NA, n_files, n_intervals^3+1))
colnames(RGB) <- c("Image", paste("RGB_", 1:n_intervals^3, sep = ""))
RGB$Image <- n_names
img <- readImage(paste(img_dir, n_names[1], sep = ""))
img <- resize(img, n_resize, n_resize)
img_data <- imageData(img)
RGB_data <- img_data
RGB_levels <- as.data.frame(table(
factor(findInterval(RGB_data[,,1], intervals_RGB), levels = 1:n_intervals),
factor(findInterval(RGB_data[,,2], intervals_RGB), levels = 1:n_intervals),
factor(findInterval(RGB_data[,,3], intervals_RGB), levels = 1:n_intervals)
))
RGB[1,2:ncol(RGB)] <- RGB_levels$Freq/(n_resize^2)
View(RGB)
View(RGB)
HSV <- data.frame(matrix(NA, n_files, n_intervals^3+1))
colnames(HSV) <- c("Image", paste("HSV_", 1:n_intervals^3, sep = ""))
HSV$Image <- n_names
rgb2hsv(img_data)
?rgb2hsv
rgb2hsv(t(img_data))
img <- readImage(paste(img_dir, n_names[1], sep = ""))
img <- resize(img, 256, 256)
rgb2hsv(t(img_data))
img_data <- imageData(img)
rgb2hsv(t(img_data))
rgb2hsv(t(as.matrix(img_data)))
temp <- as.matrix(img_data)
View(temp)
rgb2hsv(t(img))
img <- readImage(paste(img_dir, n_names[1], sep = ""))
img <- resize(img, 256, 256)
img_data <- imageData(img)
img <- readImage(paste(img_dir, n_names[1], sep = ""))
img <- resize(img, 256, 256)
img_data <- imageData(img)
imageData(img)
img <- resize(img, 128, 128)
img <- readImage(paste(img_dir, n_names[1], sep = ""))
img <- resize(img, 128, 128)
img_data <- imageData(img)
?resize
rgb2hsv(t(img_data))
rgb2hsv(t(as.matrix(img_data)))
?rgb2hsv
t(as.matrix(img_data))
temp <- as.matrix(img_data)
img <- readImage(paste(img_dir, n_names[1], sep = ""))
img <- resize(img, 128, 128)
img_data <- imageData(img)
temp <- as.matrix(img_data)
rgb2hsv(t(as.matrix(img_data)))
img <- readImage(paste(img_dir, n_names[1], sep = ""))
img <- resize(img, 128, 128)
img <- readImage(paste(img_dir, n_names[1], sep = ""))
img_resized <- cv2$resize(img, dsize=tuple(64L, 64L))
library(reticulate)
cv2 <- reticulate::import('cv2')
library(EBImage)
img_resized <- cv2$resize(img, dsize=tuple(64L, 64L))
img_resized <- cv2$resize(img, dsize=tuple(128L, 128L))
rgb2hsv(img_data)
rgb2hsv(img_data, dtype = 'uint8')
temp <- img_data[,,1]
?rgb2hsv
rgb2hsv(img_data[,,1], img_data[,,2],img_data[,,3])
dim(img_data) <- c(128*128,3)
View(img_data)
rgb2hsv(t(img_data))
HSV_data <- rgb2hsv(t(img_data))
HSV_levels <- as.data.frame(table(
factor(findInterval(HSV_data[,,1], intervals_RGB), levels = 1:n_intervals),
factor(findInterval(HSV_data[,,2], intervals_RGB), levels = 1:n_intervals),
factor(findInterval(HSV_data[,,3], intervals_RGB), levels = 1:n_intervals)
))
intervals_value <- seq(0,1,0.005, length.out = n_intervals)
intervals_value <- seq(0,0.005, length.out = n_intervals) # the limits for the levels for the V in HSV
findInterval(HSV_data[,,1], intervals_RGB)
View(HSV_data)
HSV_levels <- as.data.frame(table(
factor(findInterval(HSV_data[1,], intervals_RGB), levels = 1:n_intervals),
factor(findInterval(HSV_data[2,], intervals_RGB), levels = 1:n_intervals),
factor(findInterval(HSV_data[3,], intervals_RGB), levels = 1:n_intervals)
))
HSV[i,2:ncol(HSV)] <- HSV_levels$Freq/(n_resize^2)
HSV[1,2:ncol(HSV)] <- HSV_levels$Freq/(n_resize^2)
View(HSV)
source("../lib/features.R")
feature(img_train_dir)
color_features <- merge(RGB, HSV)
View(color_features)
color_features <- merge(RGB, HSV, by.x = Image)
color_features <- merge(RGB, HSV, by.x = "Image")
color_features <- merge(RGB, HSV, by.x = "Image", by.y = "Image")
View(color_features)
source("../lib/features.R")
feature(img_train_dir)
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(img_train_dir))
}
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(img_train_dir))
}
source("../lib/features.R")
tm_feature_train <- NA
source("../lib/features.R")
source("../lib/feature_color features.R")
tm_feature_train <- NA
install.packages("wvtool")
library("wvtool")
?lbp
ccv2$cvtColor(np_array(img, dtype='float32'), cv2$COLOR_BGR2GRAY)
cv2$cvtColor(np_array(img, dtype='float32'), cv2$COLOR_BGR2GRAY)
img_gray <- cv2$cvtColor(np_array(img, dtype='float32'), cv2$COLOR_BGR2GRAY)
lbp(img_gray)
plot(img_gray)
plot(to_ebimage(img_gray))
?to_ebimage
??to_ebimage
library("EBImage")
?to_ebimage
laplacian <- cv2$Laplacian(img, cv2$CV_64F)
plot(to_ebimage(laplacian))
library(reticulate)
cv2 <- reticulate::import('cv2')
plot(to_ebimage(img_gray))
lbp(img_gray)
temp <- lbp(img_gray)
load("~/Desktop/project-2-predictive-modelling-group-6/output/train_feature_color&lbp.RData")
if(!require("EBImage")){
source("https://bioconductor.org/biocLite.R")
biocLite("EBImage")
}
if(!require("gbm")){
install.packages("gbm")
}
if(!require("pbapply")){
install.packages("pbapply")
}
install.packages("caret")
library("caret")
library("EBImage")
library("gbm")
library("pbapply")
library(reticulate)
library("wvtool")
cv2 <- reticulate::import('cv2')
experiment_dir <- "../data/pets/" # This will be modified for different data sets.
img_train_dir  <- paste(experiment_dir, "train/", sep="")
img_test_dir   <- paste(experiment_dir, "test/", sep="")
n_names <- list.files(img_train_dir)
img_train_dir
list.files(img_train_dir)
getwd()
getwd()
knitr::opts_chunk$set(echo = TRUE)
mypath <- "../data/split_data/"
library("plyr")
# install.packages("randomForest")
# Training labels:
# train_label
load(paste(mypath, "train/train_label.Rdata", sep = ""))
# Training data:
# train_color
# train_HOG
# train_LBP
load(paste(mypath, "train/train_color.Rdata", sep = ""))
load(paste(mypath, "train/train_HOG.Rdata", sep = ""))
load(paste(mypath, "train/train_LBP.Rdata", sep = ""))
# Test labels:
# test_label
load(paste(mypath, "test/test_label.Rdata", sep = ""))
# Test data:
# test_color
# test_HOG
# test_LBP
load(paste(mypath, "test/test_color.Rdata", sep = ""))
load(paste(mypath, "test/test_HOG.Rdata", sep = ""))
load(paste(mypath, "test/test_LBP.Rdata", sep = ""))
rownames(train_color) <- 1:1600
rownames(train_HOG) <- 1:1600
rownames(train_LBP) <- 1:1600
rownames(test_color) <- 1:400
rownames(test_HOG) <- 1:400
rownames(test_LBP) <- 1:400
require(tidyverse, quietly = TRUE) # For the pipeline operator %>%
train_HOG <-
train_HOG %>%
select(-Image)
train_color <-
train_color %>%
select(-Image)
test_HOG <-
test_HOG %>%
select(-Image)
test_color <-
test_color %>%
select(-Image)
train_data <- cbind(train_label, train_LBP, train_HOG, train_color)
test_data <- cbind(test_label, test_LBP, test_HOG, test_color)
require(caret, quietly = TRUE)
require(randomForest, quietly = TRUE)
# This set-up draws from https://machinelearningmastery.com/tune-machine-learning-algorithms-in-r/
control <- trainControl(method = "repeatedcv",
number = 10,
repeats = 3,
search = "random")
seed = 1
set.seed(seed)
# This is the computationally intensive step.
start_time = Sys.time()
rf <- train(label ~ .,
data = train_data,
method = "rf",
tuneLength = 15,
ntree = 5,
trControl = control)
# This is an alternate version of optimizing the random forest
# that uses the built-in `tuneRF` function in the
# `randomForest` package to optimize the `mtry` paramter,
# which is the most important parameter to search over in random forests.
require(randomForest, quietly = TRUE)
seed = 1
set.seed(seed)
response <- training_data$label
response <- train_data$label
predictors <- train_data[3:length(training_data)]
predictors <- train_data[3:length(train_data)]
rf_alternate <- tuneRF(predictors, response, ntreeTry = 500, doBest = TRUE))
rf_alternate <- tuneRF(predictors, response, ntreeTry = 500, doBest = TRUE)
save(rf_alternate, file = "../output/rf_model.Rdata")
save(train_data, file = "../data/split_data/train/train_data.Rdata")
getwd()
getwd()
save(train_data, file = "../data/split_data/train/train_data.Rdata")
save(test_data, file = "../data/split_data/test/test_data.Rdata")
View(train_data)
rf <- train(label ~ .,
data = train_data,
method = "rf",
tuneLength = 15,
ntree = 5,
trControl = control)
train_data <- load("../data/split_data/train/train_data.Rdata")
train_data <- load("../data/split_data/train/train_data.Rdata")
getwd()
getwd()
getwd()
setwd("/Users/wcheng/Desktop/Spring 2018/data science/project-2-predictive-modelling-group-6/lib")
train_data <- load("../data/split_data/train/train_data.Rdata")
train_data <- load("../data/split_data/train/train_data.Rdata")
test_data <- load("../data/split_data/test/test_data.Rdata")
load("../data/split_data/train/train_data.Rdata")
load("../data/split_data/test/test_data.Rdata")
require(randomForest, quietly = TRUE)
seed = 1
set.seed(seed)
response <- train_data$label
predictors <- train_data[3:length(train_data)]
load("../data/split_data/output/RF-model.Rdata")
load("../data/split_data/output/rf-model.Rdata")
load("../output/rf-model.Rdata")
setwd("/Users/wcheng/Desktop/Spring 2018/data science/project-2-predictive-modelling-group-6/lib")
load("../output/rf_model.Rdata")
load("~/Desktop/Spring 2018/data science/Fall2017-project3-grp1/output/feature_train.RData")
View(train_data)
View(dat_train)
RF(train_data, test_data)
RF <- function(train_data, test_data){
require(randomForest, quietly = TRUE)
seed = 1
set.seed(seed)
response <- train_data$label
predictors <- train_data[3:length(train_data)]
rf_model <- tuneRF(predictors, response, ntreeTry = 500, doBest = TRUE)
return(rf_alternate)
}
RF(train_data, test_data)
RF <- function(train_data){
require(randomForest, quietly = TRUE)
seed = 1
set.seed(seed)
response <- train_data$label
predictors <- train_data[3:length(train_data)]
rf_model <- tuneRF(predictors, response, ntreeTry = 500, doBest = TRUE)
return(rf_alternate)
}
RF(train_data)
getwd()
load("../data/split_data/train/train_data.Rdata")
RF <- function(train_data){
require(randomForest, quietly = TRUE)
seed = 1
set.seed(seed)
response <- train_data$label
predictors <- train_data[3:length(train_data)]
rf_model <- tuneRF(predictors, response, ntreeTry = 500, doBest = TRUE)
return(rf_alternate)
}
RF(train_data)
RF_model <- RF(train_data)
train <- function(train_data, run.RF = F,run.TF = F,run.GBM = F, export = T){
### Input:
###  -  processed features from images with labels
### Output: training model specification
### load libraries
library("gbm")
### Train with gradient boosting model
if(run.RF){
RF_model <- RF(train_data)
return(RF_model)
}
if(run.tf){
TF_model <- TF(train_data)
return(TF_model)
}
if(run.GBM){
GBM_model <- GBM(train_data)
return(GBM_model)
}
RF <- function(train_data){
require(randomForest, quietly = TRUE)
seed = 1
set.seed(seed)
response <- train_data$label
predictors <- train_data[3:length(train_data)]
rf_model <- tuneRF(predictors, response, ntreeTry = 500, doBest = TRUE)
save(rf_model, file = "../output/rf_model.Rdata")
return(rf_model)
}
TF <- function(train_data){
save(tf_model, file = "../output/tf_model.Rdata")
return(TF_model)
}
GBM <- function(train_data){
save(gbm_model, file = "../output/gbm_model.Rdata")
return(GBM_model)
}
}
?tuneRF
RF_model <- train(train_data, run.RF = T)
train <- function(train_data, run.RF = F,run.TF = F,run.GBM = F, export = T){
### Input:
###  -  processed features from images with labels
### Output: training model specification
### load libraries
library("gbm")
### Train with gradient boosting model
if(run.RF){
RF_model <- RF(train_data)
return(RF_model)
}
if(run.tf){
TF_model <- TF(train_data)
return(TF_model)
}
if(run.GBM){
GBM_model <- GBM(train_data)
return(GBM_model)
}
RF <- function(train_data){
require(randomForest, quietly = TRUE)
seed = 1
set.seed(seed)
response <- train_data$label
predictors <- train_data[3:length(train_data)]
rf_model <- tuneRF(predictors, response, ntreeTry = 500, doBest = TRUE)
save(rf_model, file = "../output/rf_model.Rdata")
return(rf_model)
}
TF <- function(train_data){
save(tf_model, file = "../output/tf_model.Rdata")
return(TF_model)
}
GBM <- function(train_data){
save(gbm_model, file = "../output/gbm_model.Rdata")
return(GBM_model)
}
}
train
train(train_data, run.RF = T)
train <- function(train_data, run.RF = F,run.TF = F,run.GBM = F, export = T){
### Input:
###  -  processed features from images with labels
### Output: training model specification
### load libraries
library("gbm")
### Train with gradient boosting model
if(run.RF){
RF_model <- RF(train_data)
return(RF_model)
}
if(run.tf){
TF_model <- TF(train_data)
return(TF_model)
}
if(run.GBM){
GBM_model <- GBM(train_data)
return(GBM_model)
}
RF <- function(train_data){
require(randomForest, quietly = TRUE)
seed = 1
set.seed(seed)
response <- train_data$label
predictors <- train_data[3:length(train_data)]
rf_model <- tuneRF(predictors, response, ntreeTry = 500, doBest = TRUE)
save(rf_model, file = "../output/rf_model.Rdata")
return(rf_model)
}
TF <- function(train_data){
save(tf_model, file = "../output/tf_model.Rdata")
return(TF_model)
}
GBM <- function(train_data){
save(gbm_model, file = "../output/gbm_model.Rdata")
return(GBM_model)
}
}
load("../data/split_data/train/train_data.Rdata")
RF_model <- train(train_data, run.RF = T)
train <- function(train_data, run.RF = F,run.TF = F,run.GBM = F, export = T){
### Input:
###  -  processed features from images with labels
### Output: training model specification
### load libraries
library("gbm")
### Train with gradient boosting model
if(run.RF){
RF_model <- RF(train_data)
return(RF_model)
}
if(run.tf){
TF_model <- TF(train_data)
return(TF_model)
}
if(run.GBM){
GBM_model <- GBM(train_data)
return(GBM_model)
}
}
RF <- function(train_data){
require(randomForest, quietly = TRUE)
seed = 1
set.seed(seed)
response <- train_data$label
predictors <- train_data[3:length(train_data)]
rf_model <- tuneRF(predictors, response, ntreeTry = 500, doBest = TRUE)
save(rf_model, file = "../output/rf_model.Rdata")
return(rf_model)
}
TF <- function(train_data){
save(tf_model, file = "../output/tf_model.Rdata")
return(TF_model)
}
GBM <- function(train_data){
save(gbm_model, file = "../output/gbm_model.Rdata")
return(GBM_model)
}
load("../data/split_data/train/train_data.Rdata")
RF_model <- train(train_data, run.RF = T)
load("../data/split_data/test/test_data.Rdata")
View(test_data)
predict(RF_model$fit, newdata = test_data[,3:ncol(test_data)])
predict(RF_model, newdata = test_data[,3:ncol(test_data)])
pred <- predict(RF_model, newdata = test_data[,3:ncol(test_data)])
